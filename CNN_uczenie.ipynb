{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1826c810",
   "metadata": {},
   "source": [
    "# Preprocessing danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963dfeba",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.layers import Flatten, Dense, Conv1D, MaxPool1D, Dropout\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "pd.options.mode.chained_assignment = None\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#data = pd.read_csv('merged_data.csv')\n",
    "data = pd.read_csv('fifth-run/feats_version_5_22_acc.csv')\n",
    "data = data[~data[\"activity\"].str.contains(\"jogging\")]\n",
    "data[\"activity\"] = data[\"activity\"].replace([\"sitting\", \"lying\"], \"resting\")\n",
    "\n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "result = data[data[\"name\"].str.contains(\"kuba\")]\n",
    "\n",
    "result_train = data[data[\"name\"].str.contains(\"kuba\") == False]\n",
    "\n",
    "result_train.drop('name', axis=1, inplace=True)\n",
    "result.drop('name', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "X_train = result_train.iloc[:, :-1].values\n",
    "labels_train = result_train.iloc[:, -1].values\n",
    "\n",
    "X_test = result.iloc[:, :-1].values\n",
    "labels_test = result.iloc[:, -1].values\n",
    "\n",
    "\n",
    "encoder = LabelBinarizer()\n",
    "\n",
    "labels_train1 = encoder.fit_transform(labels_train)\n",
    "\n",
    "labels_test1 = encoder.transform(labels_test)\n",
    "\n",
    "X_test, X_val, labels_test1, labels_val1 = train_test_split(X_test, labels_test1, test_size=0.5, random_state=42)\n",
    "\n",
    "X_train = np.array(X_train).reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test = np.array(X_test).reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "X_val = np.array(X_val).reshape(X_val.shape[0], X_val.shape[1], 1)\n",
    "\n",
    "print(\"Wielkość zbioru X Train: \", X_train.shape)\n",
    "print(\"Wielkość zbioru X Test: \", X_test.shape)\n",
    "print(\"Wielkość zbioru X Validation: \", X_val.shape)\n",
    "print(\"Wielkość zbioru Y Train: \", labels_train1.shape)\n",
    "print(\"Wielkość zbioru Y Test: \", labels_test1.shape)\n",
    "print(\"Wielkość zbioru Y Validation: \", labels_val1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9c6cd1",
   "metadata": {},
   "source": [
    "## Uczenie modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f8153d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cnn_model = tf.keras.models.Sequential()\n",
    "\n",
    "cnn_model.add(Conv1D(filters=32, kernel_size=(3,), padding='same', activation=tf.keras.layers.LeakyReLU(alpha=0.000000000001), input_shape = (X_train.shape[1],1)))\n",
    "cnn_model.add(Conv1D(filters=128, kernel_size=(3,), padding='same', activation=tf.keras.layers.LeakyReLU(alpha=0.00000000000001)))\n",
    "cnn_model.add(MaxPool1D(pool_size=(2,), strides=2, padding='same'))\n",
    "cnn_model.add(Dropout(0.5))\n",
    "cnn_model.add(Flatten())\n",
    "cnn_model.add(Dense(units = 512, activation=tf.keras.layers.LeakyReLU(alpha=0.01)))\n",
    "cnn_model.add(Dense(units = 6, activation='softmax'))\n",
    "cnn_model.compile(optimizer='adam', loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
    "cnn_model.summary()\n",
    "\n",
    "[print(i.shape, i.dtype) for i in cnn_model.inputs]\n",
    "[print(o.shape, o.dtype) for o in cnn_model.outputs]\n",
    "[print(l.name, l.input_shape, l.dtype) for l in cnn_model.layers]\n",
    "\n",
    "class_mapping = {\n",
    "    0: \"schodzenie\",  \n",
    "    1: \"odpoczynek\",\n",
    "    2: \"przysiady\",\n",
    "    3: \"stanie\",\n",
    "    4: \"wchodzenie\",\n",
    "    5: \"chodzenie\" }\n",
    "\n",
    "listt =[]\n",
    "for key in class_mapping.values():\n",
    "    listt.append(key)\n",
    "\n",
    "class BestAccuracyCallback(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.best_accuracy = 0.0  \n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        val_accuracy = logs.get('val_accuracy')\n",
    "        if val_accuracy is not None and val_accuracy > self.best_accuracy:\n",
    "            self.best_accuracy = val_accuracy\n",
    "    \n",
    "    def on_train_end(self, logs=None):\n",
    "        print(f\"Best Validation Accuracy: {self.best_accuracy * 100:.2f}%\")\n",
    "        \n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    min_delta=0.01,  \n",
    "    patience=60,  \n",
    "    restore_best_weights=True\n",
    ")\n",
    "        \n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='najlepszy_model_CNNprosty.h5',  # Filepath to save the best model\n",
    "    monitor='val_accuracy',    \n",
    "    save_best_only=True,       \n",
    ")\n",
    "\n",
    "cnn_model_history = cnn_model.fit(\n",
    "    X_train, labels_train1, epochs=100, batch_size=60,\n",
    "    validation_data=(X_test, labels_test1),\n",
    "    callbacks=[early_stopping_callback, model_checkpoint],\n",
    "    verbose = 1 # Include the model checkpoint callback\n",
    ")\n",
    "\n",
    "best_model = tf.keras.models.load_model('najlepszy_model_CNNprosty.h5')\n",
    "y_pred = best_model.predict(X_val)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "labels_val_categorical = np.argmax(labels_val1, axis=1)\n",
    "classification_rep = classification_report(labels_val_categorical, y_pred_classes, target_names=listt)\n",
    "print(\"Classification Report from Best Model:\\n\", classification_rep)\n",
    "confusion_mtx = confusion_matrix(labels_val_categorical, y_pred_classes)\n",
    "accuracy = accuracy_score(labels_val_categorical, y_pred_classes)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion_mtx, annot=True, fmt='d', cmap='Blues', xticklabels=listt, yticklabels=listt)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix from Best Model')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
